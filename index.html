<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Vidi: Large Multimodal Models for Video Understanding and Editing"/>
  <meta property="og:description" content="Next-generation Intelligent Editing Tools"/>
  <meta property="og:url" content="https://bytedance.github.io/vidi-website/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/teaser.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="530"/>


  <meta name="twitter:title" content="Vidi: Large Multimodal Models for Video Understanding and Editing">
  <meta name="twitter:description" content="Next-generation Intelligent Editing Tools">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/image/teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Vidi: Large Multimodal Models for Video Understanding and Editing</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo_search.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Vidi: Large Multimodal Models for Video Understanding and Editing</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <!-- href="https://bytedance.github.io/vidi-website/" -->
                <a target="_blank">Intelligent Editing Team</a></span>
                <!-- <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span> -->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Intelligent Creation <br>ByteDance Inc.</span>
                    <span class="eql-cntrb"><small><br>San Jose/Seattle, US</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Report</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
<!--                     <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/bytedance/vidi" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-search"></i>
                  </span>
                  <span>Demo (Coming soon)</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
<!--       <video poster="" id="tree"  controls loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video> -->
      <img src="static/images/teaser.png" width="1200" height="530">
      <h2 class="subtitle has-text-centered">
        Temporal retrieval performance of different models on the proposed VUE-TR benchmark.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Humans naturally share information with those they are connected to, and video has become one of the
dominant mediums for communication and expression on the Internet. To support high-quality, large-scale
video content, modern video creation pipeline requires a comprehensive understanding of both the raw input
materials (e.g., unedited footage captured by cameras) and the editing components (e.g., visual effects).
In video editing scenarios, models must process multiple modalities (e.g., vision, audio, text) with strong
background knowledge and handle flexible input lengths (e.g., hour-long raw videos), which poses significant
challenge for traditional architectures. In this report, we introduce Vidi, a family of Large Multimodal
Models (LMMs) for a wide range of video editing scenarios. The first release focuses on temporal retrieval,
i.e., identifying the time ranges in input videos corresponding to a given text query. The model is capable
of processing hour-long videos with strong temporal understanding capability, e.g., retrieve time ranges for
certain queries. To support a comprehensive evaluation in real-world scenarios, we also present the VUE-TR
benchmark, which introduces five key advancements: 1) Video duration: spans from 20 seconds to over an
hour, which is significantly longer than existing temporal/moment retrieval datasets. 2) Audio support:
includes audio-based queries for temporal retrieval. 3) Query format: accommodates three different query
lengths/formats, i.e., keyword, phrase, and sentence. 4) Annotation quality: all ground-truth time ranges
are manually annotated for high accuracy. 5) Evaluation metric: a refined IoU metric designed to support
evaluation over multiple time ranges. Remarkably, Vidi significantly outperforms leading proprietary models,
e.g., GPT-4o and Gemini, on temporal retrieval tasks, indicating its superiority in video editing scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!--Benchmark -->
<section class="section" id="Benchmark">
  <div class="container is-max-desktop content">
    <h2 class="title">Benchmark</h2>
    <img src="static/images/data_table.png" width="1200" height="213">
    <img src="static/images/data_figure.png" width="973" height="405">
  </div>
</section>
<!--End Benchmark -->

<section class="section" id="Table">
  <div class="container is-max-desktop content">
    <h2 class="title">Qualitative Results</h2>
    <!-- <td>Video Id</td> -->
  <table class="styled-table"><tr><td>Input Video</td><td>Input Query</td><td>Duration</td><td>Ground Truth</td><td>Prediction</td><td>IOU</td><td>Result Clips</td></tr>
    <tr>
      <td><iframe width="200" src="https://www.youtube.com/embed/JtoXTI2uouA?si=Cl15eBvgZhFC-xOb" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>basketball statue</td><td>00:00:46</td><td>00:00:13-00:00:30</td><td>00:00:13-00:00:31</td><td>0.94</td>
      <td><iframe src="static/videos/JtoXTI2uouA_13_30_256.mp4" width="200" height="300"></iframe></td>
    </tr>
    <tr>
      <!-- <td>Dor8rxFro8o</td> -->
      <td><iframe width="200" src="https://www.youtube.com/embed/Dor8rxFro8o?si=9Sl-mtXtEoAqnTPq" title="YouTube video player" frameborder="0" allow="accelerometer; ; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>gymnasium</td><td>00:01:29</td><td>00:00:00-00:01:28</td><td>00:00:00-00:01:29</td><td>0.99</td>
      <!-- <td><video controls loop width="200" height="100%"><source src="static/videos/Dor8rxFro8o_0_88_256.mp4" type="video/mp4"></video></td> -->
      <td><iframe src="static/videos/Dor8rxFro8o_0_88_256.mp4" width="200"></iframe></td>
    </tr>
    <tr>
      <!-- <td>cCFE8uIHvnQ</td> -->
      <td><iframe width="200" src="https://www.youtube.com/embed/cCFE8uIHvnQ?si=QOVwh7GztjVOn8HL" title="YouTube video player" frameborder="0" allow="accelerometer; ; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>people assembling sculptures on beach</td><td>00:01:30</td><td>00:00:24-00:00:33</td><td>00:00:24-00:00:33</td><td>1.00</td>
      <!-- <td><video controls loop width="200" height="100%"><source src="static/videos/cCFE8uIHvnQ_24_32_256.mp4" type="video/mp4"></video></td> -->
      <td><iframe src="static/videos/cCFE8uIHvnQ_24_32_256.mp4" width="200"></iframe></td>
    </tr>
    <tr>
      <td><iframe width="200" src="https://www.youtube.com/embed/AYM65NL5714?si=yfbUPafw0rDdX8L9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>Euripides, has most surviving work like 'Medea' and 'The Bacchae', debut in 455 BC. He is a corner stone of greek education in the Hellenistic period.</td><td>00:05:10</td><td>00:04:22-00:04:41</td><td>00:04:20-00:04:35</td><td>0.62</td>
      <td><iframe src="static/videos/AYM65NL5714_260_274_256.mp4" width="200"></iframe></td>
    </tr>
    <tr>
      <!-- <td>Ll9xlNi2-mI</td> -->
      <td><iframe width="200" src="https://www.youtube.com/embed/Ll9xlNi2-mI?si=jxq8FSpvV8JvWfhy" title="YouTube video player" frameborder="0" allow="accelerometer; ; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>Jennifer Nagel self-introduction</td><td>00:10:02</td><td>00:00:07-00:00:16</td><td>00:00:07-00:00:17</td><td>0.90</td>
      <!-- <td><video controls loop width="200" height="100%"><source src="static/videos/Ll9xlNi2-mI_7_16_256.mp4" type="video/mp4"></video></td> -->
      <td><iframe src="static/videos/Ll9xlNi2-mI_7_16_256.mp4" width="200"></iframe></td>
    </tr>
    <tr>
      <!-- <td>MmQdTF0Grgc</td> -->
      <td><iframe width="200" src="https://www.youtube.com/embed/MmQdTF0Grgc?si=CbNBeER0gDr1P3xW" title="YouTube video player" frameborder="0" allow="accelerometer; ; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>divine wind</td><td>00:20:18</td><td>00:05:06-00:05:08</td><td>0:05:05-0:05:08</td><td>0.67</td>
      <!-- <td><video controls loop width="200" height="100%"><source src="static/videos/MmQdTF0Grgc_305_307_256.mp4" type="video/mp4"></video></td> -->
      <td><iframe src="static/videos/MmQdTF0Grgc_305_307_256.mp4" width="200"></iframe></td>
    </tr>
    <!-- <tr> -->
      <!-- <td>QE-a2L1N59Q</td> -->
      <!-- <td><iframe width="200" src="https://www.youtube.com/embed/QE-a2L1N59Q?si=8BiDpXEPkXQe8DZ5" title="YouTube video player" frameborder="0" allow="accelerometer; ; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td> -->
      <!-- <td>A presentation demonstrates the development and evolution of the market from its introduction to maturity.</td><td>00:47:43</td><td>00:06:44-00:12:38</td><td>00:06:43-00:12:32</td><td>0.98</td> -->
      <!-- <td><video controls loop width="200" height="100%"><source src="static/videos/QE-a2L1N59Q_403_751_256.mp4" type="video/mp4"></video></td> -->
      <!-- <td><iframe src="static/videos/QE-a2L1N59Q_403_751_256.mp4" width="200"></iframe></td> -->
    <!-- </tr> -->
    <tr>
      <td><iframe width="200" src="https://www.youtube.com/embed/PxHpInG6iFo?si=_Qk1_v7vjgWVsU7V" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>FTC resources</td><td>00:59:35</td><td>00:43:41-00:44:17</td><td>00:43:31-00:44:15</td><td>0.74</td>
      <td><iframe src="static/videos/PxHpInG6iFo_2611_2654_256.mp4" width="200"></iframe></td>
    </tr>
    <tr>
      <td><iframe width="200" src="https://www.youtube.com/embed/wDKzPVJ0EjI?si=XLZDokOuh-98-GYl" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></td>
      <td>North Devon Marine Pioneer</td><td>01:24:45</td><td>00:00:00-00:02:31, 00:03:58-00:06:20, 00:13:32-00:16:01, 00:16:57-00:17:00, 00:47:21-01:03:10</td><td>00:00:00-00:02:33, 00:46:56-01:03:08</td><td>0.77</td>
      <td><iframe src="static/videos/wDKzPVJ0EjI_0_152_256.mp4" width="200"></iframe>
        <iframe src="static/videos/wDKzPVJ0EjI_2816_3787_256.mp4" width="200"></iframe></td>
    </tr>
  </table>
</div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=n&d=-9L2vbfYziUTxLtDI5qacjl-usVkRyq6FQk75KfgU9U'></script>
    <!-- End of Statcounter Code -->

  </body>
  </html>

